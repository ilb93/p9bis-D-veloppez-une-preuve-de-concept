import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json

# ===============================
# CONFIG STREAMLIT
# ===============================
st.set_page_config(
    page_title="DataSpace ‚Äì Proof of Concept",
    layout="wide"
)

st.title("üìä Proof of Concept ‚Äì Am√©lioration d‚Äôun mod√®le ML")

st.markdown(
    """
    Cette application pr√©sente une **preuve de concept** comparant :

    - un **mod√®le baseline** (RidgeClassifier)
    - un **mod√®le r√©cent et plus performant** (LightGBM)

    üéØ Objectif : d√©montrer l‚Äôam√©lioration des performances via un dashboard interactif.
    """
)

# ===============================
# CHARGEMENT DES ARTEFACTS
# ===============================
@st.cache_resource
def load_artifacts():
    std_scaler = joblib.load("artifacts/std_scale.joblib")
    imputer = joblib.load("artifacts/imputer_median.joblib")
    ridge_model = joblib.load("artifacts/best_ridge.joblib")
    lgbm_model = joblib.load("artifacts/lgbm.joblib")

    with open("artifacts/metadata.json", encoding="utf-8") as f:
        metadata = json.load(f)

    return std_scaler, imputer, ridge_model, lgbm_model, metadata


std_scaler, imputer, ridge_model, lgbm_model, metadata = load_artifacts()

RAW_COLS = metadata["raw_feature_columns"]
COL_MAP = metadata["column_mapping_raw_to_lgbm"]

# ===============================
# SAISIE UTILISATEUR (POC)
# ===============================
st.subheader("üß© Saisie des variables d‚Äôentr√©e")

st.markdown(
    """
    üëâ Pour la preuve de concept, vous pouvez modifier manuellement les valeurs
    d‚Äôun individu fictif afin de comparer les pr√©dictions des mod√®les.
    """
)

input_data = {}

for col in RAW_COLS:
    input_data[col] = st.number_input(
        label=col,
        value=0.0,
        step=1.0,
        format="%.2f"
    )

input_df = pd.DataFrame([input_data])

st.subheader("üìã Donn√©es utilis√©es pour la pr√©diction")
st.dataframe(input_df)

# ===============================
# PREPROCESSING (ALIGN√â NOTEBOOK)
# ===============================
def preprocess(df_row):
    # 1Ô∏è‚É£ Imputation sur donn√©es BRUTES
    X_imputed = pd.DataFrame(
        imputer.transform(df_row),
        columns=RAW_COLS
    )

    # 2Ô∏è‚É£ Standardisation apr√®s imputation
    X_scaled = pd.DataFrame(
        std_scaler.transform(X_imputed),
        columns=RAW_COLS
    )

    # 3Ô∏è‚É£ Renommage pour LightGBM
    X_lgbm = X_scaled.rename(columns=COL_MAP)

    return X_scaled, X_lgbm


X_ridge, X_lgbm = preprocess(input_df)

# ===============================
# CHOIX DU MOD√àLE
# ===============================
st.subheader("‚öôÔ∏è Choix du mod√®le")

model_choice = st.radio(
    "S√©lectionner le mod√®le",
    (
        "Baseline ‚Äì RidgeClassifier",
        "Nouveau mod√®le ‚Äì LightGBM"
    )
)

# ===============================
# PR√âDICTION
# ===============================
st.subheader("üîÆ Pr√©diction")

if st.button("Lancer la pr√©diction"):

    if model_choice == "Baseline ‚Äì RidgeClassifier":
        prediction = ridge_model.predict(X_ridge)[0]
        score = ridge_model.decision_function(X_ridge)[0]

    else:
        prediction = lgbm_model.predict(X_lgbm)[0]
        score = lgbm_model.predict_proba(X_lgbm)[0][1]

    st.success("‚úÖ Pr√©diction effectu√©e")

    col1, col2 = st.columns(2)
    with col1:
        st.metric("Classe pr√©dite", int(prediction))
    with col2:
        st.metric("Score / Probabilit√©", round(float(score), 3))

# ===============================
# COMPARAISON DES MOD√àLES
# ===============================
st.subheader("üìä Comparaison des approches")

comparison_df = pd.DataFrame(
    {
        "Mod√®le": ["RidgeClassifier (baseline)", "LightGBM (r√©cent)"],
        "Type": ["Lin√©aire", "Ensemble d‚Äôarbres"],
        "Gestion non-lin√©arit√©s": ["‚ùå Non", "‚úÖ Oui"],
        "Performance globale": ["R√©f√©rence", "Am√©lior√©e"],
    }
)

st.table(comparison_df)

# ===============================
# CONCLUSION
# ===============================
st.subheader("‚úÖ Conclusion")

st.markdown(
    """
    - Le **RidgeClassifier** sert de **r√©f√©rence simple et robuste**.
    - Le **LightGBM**, issu d‚Äôune veille r√©cente, capte des relations non lin√©aires.
    - Les r√©sultats confirment une **am√©lioration des performances**, validant la preuve de concept.

    üöÄ Application pr√™te pour un contexte professionnel.
    """
)
