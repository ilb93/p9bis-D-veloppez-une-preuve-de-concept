import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path

# ======================================================
# CONFIG STREAMLIT
# ======================================================
st.set_page_config(
    page_title="Proof of Concept ‚Äì Scoring de risque de d√©faut",
    layout="wide"
)

st.title("üìä Proof of Concept ‚Äì Scoring de risque de d√©faut de remboursement")

st.markdown(
    """
    Cette application pr√©sente une **preuve de concept** bas√©e sur un mod√®le
    **LightGBM**, utilis√© pour estimer le **risque de d√©faut de remboursement d‚Äôun cr√©dit**.

    üëâ Les visualisations pr√©sent√©es ci-dessous sont **volontairement adapt√©es √† une lecture humaine**
    et **ne montrent pas les valeurs math√©matiques internes utilis√©es par le mod√®le**.
    """
)

# ======================================================
# CHARGEMENT DU MOD√àLE
# ======================================================
@st.cache_resource
def load_model():
    return joblib.load(Path("artifacts") / "lgbm.joblib")

model = load_model()

# ======================================================
# IMPORT CSV
# ======================================================
st.subheader("üìÇ Import du jeu de donn√©es (CSV)")

uploaded_file = st.file_uploader(
    "Importer un fichier CSV d‚Äôinf√©rence (features pr√©trait√©es)",
    type=["csv"]
)

if uploaded_file is None:
    st.info("Veuillez importer un fichier CSV pour continuer.")
    st.stop()

df = pd.read_csv(uploaded_file)
df = df.apply(pd.to_numeric, errors="coerce")

st.success("Fichier charg√© avec succ√®s")
st.write(f"Lignes : {df.shape[0]} | Colonnes : {df.shape[1]}")

# ======================================================
# S√âLECTION DES VARIABLES PERTINENTES POUR L‚ÄôEDA
# ======================================================
eda_cols = [
    col for col in df.columns
    if df[col].nunique(dropna=True) > 20
    and df[col].std(skipna=True) > 1e-6
]

# ======================================================
# ANALYSE EXPLORATOIRE ‚Äî VERSION HUMAINE
# ======================================================
st.subheader("üîç Analyse exploratoire (lecture humaine)")

st.markdown(
    """
    Les graphiques suivants positionnent les individus **relativement √† la population**
    (faible / moyen / √©lev√©), sans afficher de valeurs math√©matiques non interpr√©tables.
    """
)

# ======================================================
# GRAPHIQUE 1 ‚Äî POSITIONNEMENT RELATIF
# ======================================================
st.markdown("### Positionnement relatif d‚Äôune variable")

rel_col = st.selectbox(
    "Choisir une variable",
    eda_cols,
    key="rel_col"
)

s = df[rel_col].dropna()

bins = [-np.inf, s.quantile(0.2), s.quantile(0.4),
        s.quantile(0.6), s.quantile(0.8), np.inf]

labels = [
    "Tr√®s faible",
    "Faible",
    "Moyen",
    "√âlev√©",
    "Tr√®s √©lev√©"
]

categories = pd.cut(s, bins=bins, labels=labels)
cat_df = categories.value_counts(normalize=True).reindex(labels).fillna(0) * 100

st.bar_chart(cat_df)

st.caption(
    "R√©partition de la population par niveau relatif. "
    "Les cat√©gories sont bas√©es sur les quantiles de la population."
)

# ======================================================
# GRAPHIQUE 2 ‚Äî PROFIL SIMPLIFI√â
# ======================================================
st.markdown("### Profil global de la variable")

profile = pd.Series({
    "En dessous de la moyenne": (s < s.median()).mean() * 100,
    "Autour de la moyenne": ((s >= s.quantile(0.4)) & (s <= s.quantile(0.6))).mean() * 100,
    "Au-dessus de la moyenne": (s > s.median()).mean() * 100
})

st.bar_chart(profile)

st.caption(
    "Ce graphique synth√©tise la position de la population par rapport √† la moyenne, "
    "sans afficher de valeurs num√©riques brutes."
)

# ======================================================
# S√âLECTION D‚ÄôUN INDIVIDU
# ======================================================
st.subheader("üéØ S√©lection d‚Äôun individu")

row_id = st.slider(
    "Choisir un individu",
    min_value=0,
    max_value=len(df) - 1,
    value=0
)

input_df = df.iloc[[row_id]]
st.dataframe(input_df)

# ======================================================
# PR√âDICTION
# ======================================================
st.subheader("üìà R√©sultat de la pr√©diction")

proba = float(model.predict_proba(input_df)[0][1])
prediction = int(proba >= 0.5)

st.markdown(
    """
    **Interpr√©tation m√©tier :**

    - **Classe 0** : pas de risque de d√©faut
    - **Classe 1** : risque de d√©faut

    La probabilit√© indique le **niveau de risque estim√©**.
    """
)

col1, col2 = st.columns(2)

with col1:
    st.metric("D√©cision du mod√®le", prediction)

with col2:
    st.metric("Probabilit√© de d√©faut", f"{proba:.1%}")

# ======================================================
# ACCESSIBILIT√â
# ======================================================
st.subheader("‚ôø Accessibilit√© (WCAG ‚Äì crit√®res essentiels)")

st.markdown(
    """
    - Graphiques sans d√©pendance exclusive √† la couleur  
    - Libell√©s textuels explicites  
    - Hi√©rarchie claire des sections  
    - Aucune information transmise uniquement par des valeurs num√©riques abstraites
    """
)

# ======================================================
# CONCLUSION
# ======================================================
st.subheader("‚úÖ Conclusion")

st.markdown(
    """
    Ce dashboard pr√©sente une **preuve de concept orient√©e d√©cision**, con√ßue pour √™tre
    **compr√©hensible par des utilisateurs non techniques**.

    Les donn√©es utilis√©es par le mod√®le sont volontairement **traduites en cat√©gories lisibles**
    pour l‚Äôanalyse exploratoire, tandis que la pr√©diction repose sur un pipeline
    **math√©matiquement rigoureux et industriel**.

    Cette approche garantit √† la fois **performance du mod√®le** et **clart√© m√©tier**.
    """
)
