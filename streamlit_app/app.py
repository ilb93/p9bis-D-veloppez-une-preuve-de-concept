import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter

# ======================================================
# CONFIG STREAMLIT
# ======================================================
st.set_page_config(
    page_title="Proof of Concept ‚Äì Scoring de risque de cr√©dit",
    layout="wide"
)

st.title("üìä Proof of Concept ‚Äì Scoring de risque de d√©faut de remboursement")

st.markdown(
    """
Cette application pr√©sente une **preuve de concept** de scoring de risque bas√©e sur un mod√®le **LightGBM**.

- Les **graphiques** affichent des **valeurs m√©tier lisibles (ann√©es / euros)**  
- La **pr√©diction** utilise **les features exactement attendues par le mod√®le**
"""
)

# ======================================================
# CHARGEMENT MOD√àLE
# ======================================================
@st.cache_resource
def load_model():
    return joblib.load(Path("artifacts") / "lgbm.joblib")

model = load_model()

def get_expected_features(m):
    if hasattr(m, "booster_") and m.booster_ is not None:
        return list(m.booster_.feature_name())
    if hasattr(m, "feature_name_"):
        return list(m.feature_name_)
    raise RuntimeError("Impossible de r√©cup√©rer les features du mod√®le.")

EXPECTED_FEATURES = get_expected_features(model)

# ======================================================
# UPLOAD CSV UNIQUE
# ======================================================
st.subheader("üìÇ Import du fichier CSV")

uploaded_file = st.file_uploader(
    "Importer le fichier CSV unifi√© (ex: sample_unified.csv)",
    type=["csv"]
)

if uploaded_file is None:
    st.stop()

df = pd.read_csv(uploaded_file)
df.columns = [c.strip() for c in df.columns]

st.success("Fichier charg√© avec succ√®s")
st.write(f"Lignes : {df.shape[0]} | Colonnes : {df.shape[1]}")

st.markdown("### üìà Statistiques descriptives")
st.dataframe(df.describe().T, use_container_width=True)

# ======================================================
# OUTILS
# ======================================================
def euro_fmt(x, pos=None):
    try:
        return f"{x:,.0f} ‚Ç¨".replace(",", " ")
    except Exception:
        return ""

def clean_employment_years(s):
    s = pd.to_numeric(s, errors="coerce")
    s = s.where(s < 900, np.nan)
    s = s.where(s >= 0, 0)
    return s

def clean_age_years(s):
    s = pd.to_numeric(s, errors="coerce")
    return s.where((s >= 0) & (s <= 120), np.nan)

def clean_money(s):
    s = pd.to_numeric(s, errors="coerce")
    return s.where(s >= 0, np.nan)

# ======================================================
# VARIABLES HUMAINES
# ======================================================
human_df = pd.DataFrame({
    "√Çge (ann√©es)": clean_age_years(df["age_years"]),
    "Anciennet√© emploi (ann√©es)": clean_employment_years(df["employment_years"]),
    "Montant du cr√©dit (‚Ç¨)": clean_money(df["AMT_CREDIT"]),
    "Prix du bien (‚Ç¨)": clean_money(df["AMT_GOODS_PRICE"]),
    "Annuit√© du cr√©dit (‚Ç¨)": clean_money(df["AMT_ANNUITY"]),
})

# ======================================================
# ANALYSE EXPLORATOIRE
# ======================================================
st.subheader("üìä Analyse exploratoire ‚Äì population")

var_label = st.selectbox("Choisir une variable", human_df.columns)
series = human_df[var_label].dropna()

col_plot, col_info = st.columns([2, 1])

with col_plot:
    fig, ax = plt.subplots(figsize=(9, 4))
    ax.hist(series, bins=30, edgecolor="black")
    ax.set_title(f"Distribution ‚Äî {var_label}")
    ax.set_xlabel(var_label)
    ax.set_ylabel("Nombre d'individus")

    if "‚Ç¨" in var_label:
        ax.xaxis.set_major_formatter(FuncFormatter(euro_fmt))

    st.pyplot(fig)

with col_info:
    st.markdown("### üìå Rep√®res")
    st.metric("Min", euro_fmt(series.min()) if "‚Ç¨" in var_label else f"{series.min():.1f}")
    st.metric("M√©diane", euro_fmt(series.median()) if "‚Ç¨" in var_label else f"{series.median():.1f}")
    st.metric("Max", euro_fmt(series.max()) if "‚Ç¨" in var_label else f"{series.max():.1f}")

# ======================================================
# S√âLECTION INDIVIDU
# ======================================================
st.subheader("üéØ S√©lection d‚Äôun individu")

row_id = st.slider("Choisir un individu", 0, len(df) - 1, 0)

# ======================================================
# GRAPHIQUE POSITION INDIVIDU (TAILLE R√âDUITE DE MOITI√â)
# ======================================================
st.markdown("### üìç Position de l‚Äôindividu dans la population")

val = human_df.loc[row_id, var_label]

fig2, ax2 = plt.subplots(figsize=(9, 2))  # ‚¨ÖÔ∏è taille divis√©e par 2
ax2.hist(series, bins=30, edgecolor="black", alpha=0.7)
ax2.axvline(val, color="red", linewidth=2)
ax2.set_xlabel(var_label)
ax2.set_ylabel("Population")

if "‚Ç¨" in var_label:
    ax2.xaxis.set_major_formatter(FuncFormatter(euro_fmt))

st.pyplot(fig2)

# ======================================================
# PR√âDICTION
# ======================================================
def build_model_row(data, idx, expected):
    row = {}
    for f in expected:
        if f in data.columns:
            v = pd.to_numeric(data.loc[idx, f], errors="coerce")
            row[f] = 0.0 if pd.isna(v) else float(v)
        else:
            row[f] = 0.0
    return pd.DataFrame([row], columns=expected)

X_row = build_model_row(df, row_id, EXPECTED_FEATURES)

proba = float(model.predict_proba(X_row)[0][1])

if proba < 0.3:
    verdict = "Faible risque de cr√©dit"
elif proba < 0.6:
    verdict = "Risque de cr√©dit mod√©r√©"
else:
    verdict = "Risque de cr√©dit √©lev√©"

st.subheader("üìà R√©sultat de la pr√©diction")

c1, c2 = st.columns(2)
c1.metric("√âvaluation du profil", verdict)
c2.metric("Probabilit√© de d√©faut", f"{proba:.2%}")

# ======================================================
# CONCLUSION (R√â√âCRITE)
# ======================================================
st.subheader("‚úÖ Conclusion")

st.markdown(
    """
Cette preuve de concept d√©montre une **approche professionnelle du scoring de risque de cr√©dit**, articul√©e autour de :

- une **analyse exploratoire m√©tier**, fond√©e sur des variables directement interpr√©tables,
- une **√©valuation individuelle**, positionn√©e par rapport √† la population globale,
- une **pr√©diction algorithmique robuste**, reposant sur l‚Äôensemble des variables du mod√®le LightGBM.

L‚Äôinterface a √©t√© con√ßue pour **transformer des r√©sultats statistiques complexes en information d√©cisionnelle compr√©hensible**, √† destination de profils non techniques.

### ‚ôø Accessibilit√© & inclusion

La r√©alisation des graphiques prend en compte les **besoins des personnes en situation de handicap**, en couvrant des crit√®res essentiels des **recommandations WCAG**, notamment :
- lisibilit√© des axes et contrastes suffisants,
- limitation de la surcharge visuelle,
- hi√©rarchisation claire de l‚Äôinformation,
- r√©duction de la charge cognitive.

Ces choix garantissent une **accessibilit√© √©quitable √† l‚Äôinformation**, ind√©pendamment des capacit√©s visuelles ou cognitives.

### üéØ Cadre projet

Cette application s‚Äôinscrit dans le cadre d‚Äôun **projet de preuve de concept en data science**, visant √† d√©montrer la capacit√© √† :
- r√©pondre √† un besoin m√©tier r√©el,
- respecter les contraintes techniques d‚Äôun mod√®le industriel,
- int√©grer des consid√©rations d‚Äôaccessibilit√© et de responsabilit√© num√©rique.
"""
)
