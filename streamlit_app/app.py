import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from scipy.stats import percentileofscore

# ======================================================
# CONFIG
# ======================================================
st.set_page_config(
    page_title="Proof of Concept ‚Äì Credit Risk Scoring",
    layout="wide"
)

st.title("üìä Proof of Concept ‚Äì Credit Risk Scoring")
st.markdown(
    """
    Cette application pr√©sente une **preuve de concept de scoring de risque de cr√©dit**.
    
    üëâ Les r√©sultats affich√©s sont **adapt√©s √† une lecture humaine** :
    - aucune valeur standardis√©e,
    - aucune unit√© math√©matique interne,
    - uniquement des **comparaisons relatives √† la population**.
    """
)

# ======================================================
# MODEL
# ======================================================
@st.cache_resource
def load_model():
    return joblib.load(Path("artifacts") / "lgbm.joblib")

model = load_model()

# ======================================================
# DATA
# ======================================================
st.subheader("üìÇ Chargement des donn√©es")

uploaded_file = st.file_uploader(
    "Importer un fichier CSV (features pr√©trait√©es)",
    type=["csv"]
)

if uploaded_file is None:
    st.stop()

df = pd.read_csv(uploaded_file)
df = df.apply(pd.to_numeric, errors="coerce")

st.success(f"{df.shape[0]} lignes charg√©es")

# ======================================================
# VARIABLES M√âTIER S√âLECTIONN√âES
# ======================================================
KEY_FEATURES = [
    "AMT_CREDIT",
    "AMT_GOODS_PRICE",
    "AMT_ANNUITY",
    "DAYS_BIRTH",
    "DAYS_EMPLOYED"
]

KEY_FEATURES = [c for c in KEY_FEATURES if c in df.columns]

# ======================================================
# INDIVIDU
# ======================================================
st.subheader("üéØ S√©lection d‚Äôun individu")

row_id = st.slider(
    "Choisir un individu",
    0,
    len(df) - 1,
    0
)

individual = df.iloc[row_id]

# ======================================================
# ANALYSE HUMAINE DES VARIABLES
# ======================================================
st.subheader("üìä Analyse comparative (lecture humaine)")

for col in KEY_FEATURES:
    col_data = df[col].dropna()
    value = individual[col]

    if pd.isna(value):
        continue

    percentile = percentileofscore(col_data, value)

    # cat√©gorisation humaine
    if percentile < 20:
        level = "Tr√®s faible"
    elif percentile < 40:
        level = "Faible"
    elif percentile < 60:
        level = "Moyen"
    elif percentile < 80:
        level = "√âlev√©"
    else:
        level = "Tr√®s √©lev√©"

    st.markdown(f"### üîπ {col}")
    st.metric(
        label="Position dans la population",
        value=f"{int(percentile)}e percentile",
        delta=level
    )

    # distribution par quintiles
    quintiles = pd.qcut(col_data, 5, labels=[
        "Tr√®s faible", "Faible", "Moyen", "√âlev√©", "Tr√®s √©lev√©"
    ])

    dist = quintiles.value_counts(normalize=True).reindex(
        ["Tr√®s faible", "Faible", "Moyen", "√âlev√©", "Tr√®s √©lev√©"]
    ) * 100

    st.bar_chart(dist)

    st.caption(
        f"La valeur de cet individu se situe dans la cat√©gorie **{level}** "
        f"par rapport √† l‚Äôensemble de la population."
    )

# ======================================================
# PR√âDICTION
# ======================================================
st.subheader("üìà R√©sultat du mod√®le")

proba = float(model.predict_proba(individual.to_frame().T)[0][1])
prediction = int(proba >= 0.5)

col1, col2 = st.columns(2)

with col1:
    st.metric("D√©cision du mod√®le", "Risque" if prediction else "Pas de risque")

with col2:
    st.metric("Probabilit√© de d√©faut", f"{proba:.1%}")

# ======================================================
# CONCLUSION
# ======================================================
st.subheader("‚úÖ Conclusion")

st.markdown(
    """
    Cette preuve de concept met en √©vidence une **approche orient√©e d√©cision** :
    - les calculs internes du mod√®le sont masqu√©s,
    - les r√©sultats sont **standardis√©s pour l‚Äôhumain** via des percentiles,
    - seules des **variables m√©tier pertinentes** sont analys√©es.

    üëâ Cette d√©marche permet de concilier **rigueur data science**  
    et **compr√©hension m√©tier**, condition indispensable √† l‚Äôusage r√©el
    d‚Äôun mod√®le de scoring.
    """
)
