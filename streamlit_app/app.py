import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
from pathlib import Path

# ======================================================
# CONFIG STREAMLIT
# ======================================================
st.set_page_config(
    page_title="Proof of Concept ‚Äì Scoring de risque de d√©faut",
    layout="wide"
)

st.title("üìä Proof of Concept ‚Äì Scoring de risque de d√©faut de remboursement")

st.markdown(
    """
    Cette application pr√©sente une **preuve de concept** bas√©e sur un mod√®le
    **LightGBM**, utilis√© pour estimer le **risque de d√©faut de remboursement d‚Äôun cr√©dit**.

    Le dashboard combine :
    - une **analyse exploratoire des donn√©es** ;
    - la **r√©partition des classes** ;
    - la **s√©lection d‚Äôun individu** ;
    - l‚Äô**estimation du risque de d√©faut**.
    """
)

# ======================================================
# CHARGEMENT DES ARTEFACTS
# ======================================================
@st.cache_resource
def load_artifacts():
    artifacts_path = Path("artifacts")

    lgbm_model = joblib.load(artifacts_path / "lgbm.joblib")

    with open(artifacts_path / "metadata.json", encoding="utf-8") as f:
        metadata = json.load(f)

    return lgbm_model, metadata


lgbm_model, metadata = load_artifacts()

RAW_COLS = metadata["raw_feature_columns"]
COL_MAP = metadata["column_mapping_raw_to_lgbm"]

# ======================================================
# IMPORT DU CSV
# ======================================================
st.subheader("üìÇ Import du jeu de donn√©es (CSV)")

uploaded_file = st.file_uploader(
    "Importer un fichier CSV (donn√©es d‚Äôinf√©rence)",
    type=["csv"]
)

if uploaded_file is None:
    st.info("Veuillez importer un fichier CSV pour continuer.")
    st.stop()

df = pd.read_csv(uploaded_file)

st.success("Fichier charg√© avec succ√®s")
st.write(f"Nombre de lignes : {df.shape[0]} | Nombre de colonnes : {df.shape[1]}")
st.dataframe(df.head())

# ======================================================
# CONTR√îLE DES COLONNES
# ======================================================
missing_cols = set(RAW_COLS) - set(df.columns)
extra_cols = set(df.columns) - set(RAW_COLS)

if missing_cols:
    st.error(f"Colonnes manquantes : {missing_cols}")
    st.stop()

if extra_cols:
    st.warning(f"Colonnes ignor√©es : {extra_cols}")

df = df[RAW_COLS]

# ======================================================
# ANALYSE EXPLORATOIRE
# ======================================================
st.subheader("üîç Analyse exploratoire des donn√©es")

st.markdown("### Statistiques descriptives")
st.dataframe(df.describe().T)

numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

st.markdown("### Distribution d‚Äôune variable num√©rique")
selected_col = st.selectbox("Choisir une variable num√©rique", numeric_cols)

st.bar_chart(df[selected_col].value_counts().sort_index())

st.markdown("### Variables avec le plus de valeurs manquantes")
missing_ratio = df.isna().mean().sort_values(ascending=False).head(20)
st.bar_chart(missing_ratio)

st.info(
    "Les valeurs manquantes sont fr√©quentes dans ce type de donn√©es "
    "et sont **nativement prises en charge par LightGBM**."
)

# ======================================================
# R√âPARTITION DES CLASSES (SUR LE DATASET D‚ÄôINF√âRENCE)
# ======================================================
st.subheader("üìä R√©partition estim√©e des classes (dataset charg√©)")

st.markdown(
    """
    Cette section pr√©sente une **estimation de la r√©partition des classes**
    obtenue en appliquant le mod√®le LightGBM sur l‚Äôensemble du jeu de donn√©es charg√©.
    Elle permet d‚Äôillustrer le **d√©s√©quilibre naturel** du probl√®me de d√©faut de cr√©dit.
    """
)

# Pr√©paration des donn√©es pour LightGBM
X_all = df.rename(columns=COL_MAP).copy()

for col in X_all.columns:
    X_all[col] = pd.to_numeric(X_all[col], errors="coerce")

# Pr√©dictions globales
probas_all = lgbm_model.predict_proba(X_all)[:, 1]
preds_all = (probas_all >= 0.5).astype(int)

class_dist = pd.Series(preds_all).value_counts(normalize=True).sort_index() * 100
class_dist_df = class_dist.rename(index={
    0: "Classe 0 ‚Äì Pas de d√©faut",
    1: "Classe 1 ‚Äì D√©faut"
}).round(2)

st.bar_chart(class_dist_df)

st.markdown(
    """
    - **Classe 0** : client sans risque de d√©faut  
    - **Classe 1** : client pr√©sentant un risque de d√©faut  

    La pr√©dominance de la classe 0 est coh√©rente avec la **r√©alit√© m√©tier** :
    les d√©fauts de remboursement restent **minoritaires**.
    """
)

# ======================================================
# S√âLECTION D‚ÄôUN INDIVIDU
# ======================================================
st.subheader("üéØ S√©lection d‚Äôun individu")

row_id = st.slider(
    "Choisir un individu",
    min_value=0,
    max_value=len(df) - 1,
    value=0
)

input_df = df.iloc[[row_id]]
st.dataframe(input_df)

# ======================================================
# PR√âDICTION INDIVIDUELLE
# ======================================================
st.subheader("üìà R√©sultat de la pr√©diction")

X_lgbm = input_df.rename(columns=COL_MAP).copy()

for col in X_lgbm.columns:
    X_lgbm[col] = pd.to_numeric(X_lgbm[col], errors="coerce")

proba = float(lgbm_model.predict_proba(X_lgbm)[0][1])
prediction = int(proba >= 0.5)

st.markdown("### Interpr√©tation de la pr√©diction")

st.markdown(
    """
    - **Classe 0** : le client ne pr√©sente **pas de risque de d√©faut de remboursement**
    - **Classe 1** : le client pr√©sente un **risque de d√©faut de remboursement**

    La probabilit√© correspond √† **l‚Äôestimation du risque de d√©faut pour la classe 1**.
    """
)

col1, col2 = st.columns(2)

with col1:
    st.metric("Risque de d√©faut estim√©", prediction)

with col2:
    st.metric("Probabilit√© de d√©faut", round(proba, 3))

# ======================================================
# CONCLUSION
# ======================================================
st.subheader("‚úÖ Conclusion")

st.markdown(
    """
    Ce dashboard illustre l‚Äôutilisation d‚Äôun **mod√®le r√©cent (LightGBM)** pour le
    **scoring de risque de cr√©dit**.

    - L‚Äôanalyse exploratoire permet de comprendre la structure et la qualit√© des donn√©es.
    - La r√©partition des classes met en √©vidence le **d√©s√©quilibre naturel** du probl√®me.
    - La pr√©diction individuelle illustre concr√®tement l‚Äôapport du mod√®le.
    """
)
