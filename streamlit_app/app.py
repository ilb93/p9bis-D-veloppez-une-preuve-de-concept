import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter

# ======================================================
# CONFIG STREAMLIT
# ======================================================
st.set_page_config(
    page_title="Proof of Concept ‚Äì Scoring de risque de cr√©dit",
    layout="wide"
)

st.title("üìä Proof of Concept ‚Äì Scoring de risque de d√©faut de remboursement")

st.markdown(
    """
Cette application pr√©sente une **preuve de concept** de scoring de risque bas√©e sur un mod√®le **LightGBM**.

- Les **graphiques** affichent des **valeurs m√©tier lisibles (ann√©es / euros)**  
- La **pr√©diction** utilise **les features exactement attendues par le mod√®le**
"""
)

# ======================================================
# CHARGEMENT MOD√àLE
# ======================================================
@st.cache_resource
def load_model():
    return joblib.load(Path("artifacts") / "lgbm.joblib")

model = load_model()

def get_expected_features(m):
    """R√©cup√®re la liste exacte des features attendues par LightGBM."""
    if hasattr(m, "booster_") and m.booster_ is not None:
        return list(m.booster_.feature_name())
    if hasattr(m, "feature_name_"):
        return list(m.feature_name_)
    raise RuntimeError("Impossible de r√©cup√©rer la liste des features attendues par le mod√®le.")

EXPECTED_FEATURES = get_expected_features(model)

# ======================================================
# UPLOAD CSV UNIQUE (comme √† l'origine)
# ======================================================
st.subheader("üìÇ Import du fichier CSV (unique)")

uploaded_file = st.file_uploader(
    "Importer le fichier CSV unifi√© (ex: sample_unified.csv / sample_unified.csv)",
    type=["csv"]
)

if uploaded_file is None:
    st.info("Veuillez importer un fichier CSV pour continuer.")
    st.stop()

df = pd.read_csv(uploaded_file)
df.columns = [c.strip() for c in df.columns]

st.success("Fichier charg√© avec succ√®s")
st.write(f"Lignes : {df.shape[0]} | Colonnes : {df.shape[1]}")
st.dataframe(df.head())

# ======================================================
# ‚úÖ TABLEAU DESCRIPTIF AU D√âBUT (CE QUE TU DEMANDAIS)
# ======================================================
st.subheader("üìä Statistiques descriptives (donn√©es import√©es)")

# Pour √©viter un describe illisible sur 310 colonnes, on propose 2 vues :
tab1, tab2 = st.tabs(["Describe (toutes colonnes num√©riques)", "Describe (5 variables m√©tier)"])

with tab1:
    numeric_df = df.select_dtypes(include=[np.number]).copy()
    if numeric_df.shape[1] == 0:
        st.info("Aucune colonne num√©rique d√©tect√©e.")
    else:
        st.dataframe(numeric_df.describe().T.round(3), use_container_width=True)

# ======================================================
# OUTILS : formatters & nettoyage
# ======================================================
def euro_fmt(x, pos=None):
    try:
        return f"{x:,.0f} ‚Ç¨".replace(",", " ")
    except Exception:
        return str(x)

def euro_str(x):
    try:
        return f"{x:,.0f} ‚Ç¨".replace(",", " ")
    except Exception:
        return str(x)

def pick_best_human_column(base_name: str, data: pd.DataFrame, money=False):
    """
    Si ton CSV contient AMT_CREDIT + AMT_CREDIT.1 etc, on choisit la version "humaine".
    Heuristique : on prend la colonne dont la m√©diane ABS est la plus grande (z-score ~0).
    """
    candidates = [c for c in data.columns if c == base_name or c.startswith(base_name + ".")]
    if not candidates:
        return None

    best_col = None
    best_score = -np.inf

    for c in candidates:
        s = pd.to_numeric(data[c], errors="coerce")
        med_abs = np.nanmedian(np.abs(s.values))
        score = med_abs + (1000 if (money and med_abs > 1000) else 0)
        if score > best_score:
            best_score = score
            best_col = c

    return best_col

def clean_employment_years(series: pd.Series) -> pd.Series:
    """
    Correction logique :
    - 1000 = sentinelle -> NaN (sinon histogramme cass√©)
    - n√©gatif -> 0
    """
    s = pd.to_numeric(series, errors="coerce")
    s = s.where(~(s >= 900), np.nan)  # 1000 -> NaN
    s = s.where(s >= 0, 0)
    return s

def clean_age_years(series: pd.Series) -> pd.Series:
    s = pd.to_numeric(series, errors="coerce")
    s = s.where((s >= 0) & (s <= 120), np.nan)
    return s

def clean_money(series: pd.Series) -> pd.Series:
    s = pd.to_numeric(series, errors="coerce")
    s = s.where(s >= 0, np.nan)
    return s

# ======================================================
# CONSTRUCTION DES 5 VARIABLES "HUMAINES"
# ======================================================
st.subheader("üîç Variables m√©tiers (lisibles)")

age_col = "age_years" if "age_years" in df.columns else None
emp_col = "employment_years" if "employment_years" in df.columns else None

credit_col = pick_best_human_column("AMT_CREDIT", df, money=True)
goods_col  = pick_best_human_column("AMT_GOODS_PRICE", df, money=True)
annuity_col = pick_best_human_column("AMT_ANNUITY", df, money=True)

missing_human = []
if age_col is None: missing_human.append("age_years")
if emp_col is None: missing_human.append("employment_years")
if credit_col is None: missing_human.append("AMT_CREDIT")
if goods_col is None: missing_human.append("AMT_GOODS_PRICE")
if annuity_col is None: missing_human.append("AMT_ANNUITY")

if missing_human:
    st.warning(
        "Colonnes 'humaines' manquantes : " + ", ".join(missing_human) +
        "\n‚û°Ô∏è Les graphes m√©tier ne pourront pas √™tre complets tant que ces colonnes n'existent pas."
    )

human_df = pd.DataFrame(index=df.index)

if age_col:
    human_df["√Çge (ann√©es)"] = clean_age_years(df[age_col])
if emp_col:
    human_df["Anciennet√© emploi (ann√©es)"] = clean_employment_years(df[emp_col])
if credit_col:
    human_df["Montant du cr√©dit (‚Ç¨)"] = clean_money(df[credit_col])
if goods_col:
    human_df["Prix du bien (‚Ç¨)"] = clean_money(df[goods_col])
if annuity_col:
    human_df["Annuit√© du cr√©dit (‚Ç¨)"] = clean_money(df[annuity_col])

st.write("Colonnes utilis√©es pour les 5 variables m√©tier :")
st.code(
    "\n".join([
        f"age_years -> {age_col}",
        f"employment_years -> {emp_col}",
        f"AMT_CREDIT -> {credit_col}",
        f"AMT_GOODS_PRICE -> {goods_col}",
        f"AMT_ANNUITY -> {annuity_col}",
    ])
)

with tab2:
    if human_df.shape[1] == 0:
        st.info("Aucune variable m√©tier exploitable.")
    else:
        st.dataframe(human_df.describe().T.round(2), use_container_width=True)

# ======================================================
# ANALYSE EXPLORATOIRE (GRAPHIQUE 1 + REP√àRES)
# ======================================================
st.subheader("üìà Analyse exploratoire ‚Äì population (valeurs humaines)")

if human_df.shape[1] == 0:
    st.stop()

var_label = st.selectbox("Choisir une variable", list(human_df.columns))
series = human_df[var_label].dropna()

col_plot, col_info = st.columns([2, 1])

with col_plot:
    fig, ax = plt.subplots(figsize=(9, 4))
    ax.hist(series.values, bins=30, edgecolor="black")
    ax.set_title(f"Distribution ‚Äî {var_label}")
    ax.set_xlabel(var_label)
    ax.set_ylabel("Nombre d'individus")

    # Format ‚Ç¨ sur l‚Äôaxe si variable mon√©taire
    if "‚Ç¨" in var_label:
        ax.xaxis.set_major_formatter(FuncFormatter(euro_fmt))

    st.pyplot(fig)

with col_info:
    st.markdown("### üìå Rep√®res")

    if len(series) == 0:
        st.write("Aucune donn√©e exploitable.")
    else:
        vmin = float(np.nanmin(series.values))
        vmean = float(np.nanmean(series.values))
        vmax = float(np.nanmax(series.values))

        # ‚úÖ CE QUE TU DEMANDAIS : Min / Moyenne / Max (pas m√©diane)
        if "‚Ç¨" in var_label:
            st.metric("Min", euro_str(vmin))
            st.metric("Moyenne", euro_str(vmean))
            st.metric("Max", euro_str(vmax))
        else:
            st.metric("Min", f"{vmin:.1f}")
            st.metric("Moyenne", f"{vmean:.1f}")
            st.metric("Max", f"{vmax:.1f}")

    st.markdown("### ‚ÑπÔ∏è Interpr√©tation")
    if "√Çge" in var_label:
        st.info("√Çge r√©el (ann√©es). Valeur directement interpr√©table.")
    elif "Anciennet√©" in var_label:
        st.info(
            "Anciennet√© r√©elle (ann√©es).\n\n"
            "‚ö†Ô∏è La valeur 1000 est une sentinelle et a √©t√© convertie en valeur manquante pour ne pas casser l'histogramme."
        )
    else:
        st.info("Variable mon√©taire r√©elle (euros). Distribution souvent asym√©trique (queue √† droite).")

# ======================================================
# PR√âDICTION (features mod√®le)
# ======================================================
st.subheader("üéØ S√©lection d‚Äôun individu + pr√©diction")

row_id = st.slider(
    "Choisir un individu",
    min_value=0,
    max_value=len(df) - 1,
    value=0
)

# ‚úÖ 2e graphique demand√© : sous la s√©lection d‚Äôindividu, position sur la variable s√©lectionn√©e
st.markdown("### üìç Position de l‚Äôindividu dans la distribution (variable choisie)")

indiv_value = human_df.loc[row_id, var_label] if var_label in human_df.columns else np.nan

fig2, ax2 = plt.subplots(figsize=(9, 4))
ax2.hist(series.values, bins=30, edgecolor="black", alpha=0.75)
if pd.notna(indiv_value):
    ax2.axvline(float(indiv_value), linestyle="--", linewidth=2, color="red", label="Individu s√©lectionn√©")
    ax2.legend()

ax2.set_title(f"Position de l‚Äôindividu ‚Äî {var_label}")
ax2.set_xlabel(var_label)
ax2.set_ylabel("Nombre d'individus")

if "‚Ç¨" in var_label:
    ax2.xaxis.set_major_formatter(FuncFormatter(euro_fmt))

st.pyplot(fig2)

# ======================================================
# Construire la ligne mod√®le EXACTE (anti erreurs LightGBM)
# ======================================================
def build_model_row(data: pd.DataFrame, idx: int, expected_features: list[str]) -> pd.DataFrame:
    """
    Reconstruit une ligne avec EXACTEMENT :
    - colonnes attendues
    - bon ordre
    - dtypes num√©riques
    - g√®re les colonnes suffix√©es (.1, .2...) si collisions
    """
    colset = set(data.columns)
    row_dict = {}

    for f in expected_features:
        if f in colset:
            src = f
        else:
            src = None
            for k in range(1, 10):
                cand = f"{f}.{k}"
                if cand in colset:
                    src = cand
                    break

        if src is None:
            row_dict[f] = 0.0
        else:
            val = pd.to_numeric(data.loc[idx, src], errors="coerce")
            row_dict[f] = 0.0 if pd.isna(val) else float(val)

    return pd.DataFrame([row_dict], columns=expected_features)

X_row = build_model_row(df, row_id, EXPECTED_FEATURES)

# ======================================================
# Affichage profil humain (5 variables)
# ======================================================
st.markdown("### üë§ Profil (variables m√©tier)")

human_profile = human_df.loc[[row_id]].copy()

# joli format tableau
for c in human_profile.columns:
    if "‚Ç¨" in c:
        human_profile[c] = human_profile[c].apply(lambda x: euro_str(x) if pd.notna(x) else "")
    else:
        human_profile[c] = human_profile[c].apply(lambda x: f"{x:.1f}" if pd.notna(x) else "")

st.dataframe(human_profile, use_container_width=True)

# ======================================================
# PR√âDICTION + TEXTE M√âTIER (pas "pas de d√©faut")
# ======================================================
st.subheader("üìà R√©sultat de la pr√©diction")

try:
    proba = float(model.predict_proba(X_row)[0][1])

    # Seuil (tu peux le laisser √† 0.5)
    threshold = 0.5
    is_risky = (proba >= threshold)

    c1, c2 = st.columns(2)

    with c1:
        # ‚úÖ message m√©tier demand√©
        if is_risky:
            st.metric("D√©cision (lecture m√©tier)", "‚ö†Ô∏è Profil √† risque (danger potentiel)")
        else:
            st.metric("D√©cision (lecture m√©tier)", "‚úÖ Profil non dangereux (risque faible)")

    with c2:
        st.metric("Probabilit√© estim√©e de d√©faut", f"{proba:.2%}")

    # Bloc explicatif
    if is_risky:
        st.error(
            "Interpr√©tation : la probabilit√© de d√©faut est √©lev√©e.\n\n"
            "üëâ En contexte cr√©dit, ce profil est **potentiellement dangereux** et justifie une **analyse approfondie** "
            "(revenus, garanties, stabilit√©, etc.)."
        )
    else:
        st.success(
            "Interpr√©tation : la probabilit√© de d√©faut est faible.\n\n"
            "üëâ En contexte cr√©dit, ce profil est **plut√¥t non dangereux** et compatible avec une d√©cision favorable "
            "(selon la politique de risque)."
        )

except Exception as e:
    st.error(
        "Erreur lors de la pr√©diction.\n\n"
        "Cause la plus fr√©quente : colonnes/features non align√©es avec le mod√®le.\n\n"
        f"D√©tail : {type(e).__name__} ‚Äî {e}"
    )
    st.stop()

# ======================================================
# CONCLUSION
# ======================================================
st.subheader("‚úÖ Conclusion")

st.markdown(
    """
- ‚úÖ **1 seul fichier CSV** (comme √† l'origine)
- ‚úÖ **Describe** visible d√®s le d√©but
- ‚úÖ Graphique population avec **Min / Moyenne / Max**
- ‚úÖ Second graphique : **position de l‚Äôindividu** dans la distribution
- ‚úÖ R√©sultat en **langage m√©tier** (‚Äúdangereux / non dangereux‚Äù)

Si tu vois encore une erreur LightGBM, c‚Äôest uniquement si ton CSV ne contient pas les features ML attendues :
ici on reconstruit pr√©cis√©ment la ligne mod√®le (y compris si les colonnes sont suffix√©es `.1`, `.2`, etc.).
"""
)
